---
title: "Oxford Spring School in Advanced Research Methods"
author:
  name: Arun Frey & Christopher Barrie
  affiliation: University of Oxford & University of Edinburgh
output: 
  html_document:
    theme: flatly
    highlight: haddock
    # code_folding: show
    toc: yes
    toc_depth: 4
    toc_float: yes
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,  cache = T)
```

# Using Twitter for Social Science Research

This online tutorial is designed to give you some first hands-on experience with accessing and analysing Twitter data for social science research. 

The content covered in this tutorial is by no means exhaustive---it is designed to give you a first taste of what you can do with data from the Twitter API.

## What's covered
In this tutorial you will learn how to: 

* Get developers access credentials to Twitter data

* Use the `rtweet` package to query the Twitter API

* collect different types of data on protest


## Setup

### Installing `R`

We will be using `R` in the exercises below and will assume some familiarity with the programming language. 

If you haven't used `R` before or would like to refresh your memory, a great point of reference is the book "[_R For Data Science_](https://r4ds.had.co.nz)" by Hadley Wickham. 

You can install `R` by clicking [here](https://www.r-project.org). We also recommend using [RStudio](https://www.rstudio.com) for an easy-to-use development environment. 

### Packages

We will be using the following packages in the exercise, so make sure to have them installed and loaded. 

```{r install, eval = F, message=F}
# install packages (you only need to do this once)
install.packages("tidyverse")
install.packages("rtweet")
install.packages("kableExtra")
library(devtools)
install_github("pablobarbera/twitter_ideology/pkg/tweetscores")
```

```{r load, message = F}
# load packages
library(tidyverse)
library(rtweet)
library(kableExtra)
library(sp)
library(rgdal)
library(sf)
library(tweetscores)

# setting the plot theme
theme_set(theme_minimal())
```

## Connect to Twitter's API

Below we will briefly describe how to obtain access to Twitter's API. For a more detailed description of the authenticaction process, read the following vignette by Michael W. Kearney, the creator of the package. 

```{r auth, eval = F, message=F}
vignette("auth", package = "rtweet")
```


To connect to Twitter's API, you need a **consumer key** and a **consumer secret**, both of which you get by creating a Twitter App. 

To create an app, you will first need to apply for a developer account. To do so, create a Twitter acount or log into your existing one, and go to the Twitter [developer portal](https://developer.twitter.com/en). 

Click on _Apply_ in the navigation bar on the top right of the page, and fill in all the relevant information before submitting your application. Your application will then be reviewed by Twitter before access is granted. This might take hours or days. 

Once you have acquired a developers account, navigate to [developer.twitter.com/apps](developer.twitter.com/apps) and "Create a New App". This includes the name, description and reasons of use for the app. This is Chris' account, and you can see that he has registered several apps for different purposes.

![](images/twitterdev3.png){width=100%}

After creating an app, you will be given a **consumer key** (or "API key") and **consumer secret** (or "API secret key"), which you will use to interact with the Twitter API. You **MUST** make a record of these. 

Select your Twitter app and click on the tab labelled "keys and tokens". Click on "Create" to obtain your four keys, and copy and paste them into an R script file in order to create and permanently store your access token. 

```{r auth2, eval = F, message=F}

## store api keys (these are fake example values; replace with your own keys)
api_key <- "afYS1vbIlPAj016E30c4W1fiK"
api_secret_key <- "bI93kqnqFoNCrZFbsjAWHD4gJ91LQAhdCJXCj3yscfuULtNkuu"
access_token <- "9531451262-wK2EmA942kxZYIwa5LMKZoQA4Xc2uyIiEwu2YXL"
access_token_secret <- "3vpiSGKg1fIPQtxc5d5ESiFlZQpfbknEN1f1m2xe5byw7"

## authenticate via web browser
token <- create_token(
  app = "OSS Research",
  consumer_key = api_key,
  consumer_secret = api_key_secret,
  access_token = access_token,
  access_secret = access_token_secret
)
```

The `create_token()` function will save your access token as an environment variable for you. This way, the `rtweet` package will automatically find the token next time you try to access the Twitter API. 

Once you have all of these keys and tokens recorded somewhere safe, you are ready to collect data!


## Querying the Twitter API with `rtweet`

The `rtweet` package makes it very easy to collect and analyse Twitter data, including individual tweets, or follower and friendship networks.

Let's begin by collecting the last tweets mentioning the hashtag #BLM or #BlackLivesMatter. We are collecting 1500 tweets here, but you can choose a higher or lower number of tweets. Note that, to return more than 18,000 tweets in a single call, users must set `retryonratelimit = TRUE`. Here, we have set `include_rts = FALSE` meaning that all of our tweets are original tweets rather than retweets.

```{r searchtwitter, message = F, eval =FALSE}
blm_tweets <- search_tweets("#BLM OR #BlackLivesMatter", 
                           n = 1500, include_rts = FALSE)
```

```{r, echo=F}
blm_tweets <- readRDS("data/BLMtweets.rds")
```

The Twitter API allows us to retrieve a lot of information about tweets and users, but let's stick with a few for now. 

```{r head data, echo = F, message = F}
# install.packages(kableExtra)
library(kableExtra)

blm_tweets %>% 
  arrange(created_at) %>%
  select(created_at, screen_name, text) %>%
  tail(5) %>%
  kbl() %>%
  kable_styling(c("striped", "hover", "condensed", "responsive"))
```

These tweets all occur within quick succession of each other (Note: here, the tweets were collected in advance of the workshop, explaining why the dates are not more recent). In fact, we can visualise the frequency of the tweets. We could use the `ggplot` package for this, but `rtweet` already has a built in function to easily visualise time serie of Twitter data.

```{r plot timeline, message = F}
# plot a time series of all tweets in our data.
ts_plot(blm_tweets, "1 hour") + 
  ylab("Number of tweets") 
```

We can see that all 15,000 tweets capture only one day of the online discourse surrounding Black Lives Matter on Twitter. What's more, the plot reveals that users are more active during certain periods of the day--right before sleep and in the early afternoon. 


# Studying protests using Twitter 

Next, we turn our attention to using Twitter data to study protest events, and focus on the 2017 Women's March protests. Protests are notoriously hard to survey, and Twitter can potentially provide us with valuable insights into who is participating in a demonstration. 

Below is a map of all geolocated tweets that were sent on January 21, 2017, the day of the Women's March protest, showing that users across the world tweeted about the event.

```{r load WM data, echo = F, warning=F, message = F}
# load raw women's march data
wm_geo <- readRDS("data/geo_raw.rds") %>% 
  mutate_at(c("lon", "lat"), as.numeric)

# generate world data
world <- map_data("world")

# plot data

ggplot() +
    geom_map(data = world, map = world,
             aes(long, lat, map_id = region),
             color = "black", fill = "lightgray", size = 0.1) +
  geom_point(data = wm_geo, 
             aes(x = lon, y = lat), 
             color = "red", shape = 3, alpha = 0.6) + 
  theme_void()
```

```{r}
#order must be long/lat
xy <- wm_geo[,c(1,2)]
points <- SpatialPointsDataFrame(coords = xy, data = xy,
                               proj4string = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))

plot(points)

```

These data have been stripped of user identifying information, including user name, bio etc. Instead we just have two columns: latitude and longitude. The points are from all tweets that contained in the #WomensMarch. When we plot the simple latitude and longitude of the points, we can make out the vague outline of countries. This becomes clearer once we convert the latitude and longitude columns into its proper object class--a "SpatialPointsDataFrame". By doing this, we can set the CRS or "Coordinate Reference System," which controls the "projection" of the map we wish to visualize--i.e., how it looks. For more info. on map projections, see [this guide](https://docs.qgis.org/2.8/en/docs/gentle_gis_introduction/coordinate_reference_systems.html).


```{r, message=F, warning=F, eval=F}
route50 <- readOGR("shapes/wm_route_example50.shp")
route100 <- readOGR("shapes/wm_route_example100.shp")
route1000 <- readOGR("shapes/wm_route_example1000.shp")
```

We first read in three shapefiles. Each of these have been created by drawing a buffer of increasing sizes around the route of the 2017 Washington D.C. Women's March. 

```{r, message=F, warning=F, include=F}
library(magick)
route50 <- readOGR("shapes/wm_route_example50.shp")
route100 <- readOGR("shapes/wm_route_example100.shp")
route1000 <- readOGR("shapes/wm_route_example1000.shp")

routeimg <- image_read("images/wm_march_map.jpg")

```

We can compare these to the original march route below:

```{r}
par(mfrow=c(2,2))
plot(routeimg)
plot(route50, main="50m buffer")
plot(route100, main="100m buffer")
plot(route1000, main="1000m buffer")
```

We demonstrate below, however, that it is not completely necessary to use these more accurate geographic projections of protest routes. In fact, the use of a rectangular bounding box is able to capture these same protestors, with limited cost in terms of inaccuracy. To find the coordinates of a bounding box, we recommend using the open-source OpenStreetMap platform.

As shown below, by searching a location in OpenStreetMap, and selecting the "Export" option at the top of the window, we are able to view the coordinates of the left-upper and right-lower diagonals of the map displayed in the viewer window. The user can zoom in and out on this map in order to select an appropriate geographical area.

```{r, message=F, warning=F, echo=F}
osmimg <- image_read("images/osm_figure.png")
plot(osmimg)
```

To generate a rectangular bounding box object from these four coordinates, we simply need to combine them into a matrix for the purposes of plotting. We can then convert this into a spatial object, and assign the relevant CRS--the same as we assigned to our spatial points above. We have labelled the coordinates in this image. From these coordinates, we can easily now generate a SpatialPolygons bounding box by combing the x1, y1, x2, and y2 coordinates into a matrix

```{r, message=F, warning=F}
#bounding box
x1<- -77.0722
y1<- 38.9145
x2 <- -76.9786
y2 <- 38.8660
coords = matrix(c(x1, y1,
                  x1,y2,
                  x2,y2,
                  x2,y1,
                  x1,y1),
                ncol = 2, byrow = TRUE)
P1 <- Polygon(coords)
bb <- SpatialPolygons(list(Polygons(list(P1), ID = "a")), 
                      proj4string=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))

plot(bb)

```

We compare our bounding box shape to our route buffer shapes below. 

```{r}
#set consistent CRS
CRS.new<-CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
proj4string(route50) <- CRS.new 
proj4string(route100) <- CRS.new 
proj4string(route1000) <- CRS.new 

par(mfrow=c(2,4))
plot(route50)
plot(route100)
plot(route1000)
plot(bb)
plot(bb)
plot(route50,add=T)
plot(bb)
plot(route100,add=T)
plot(bb)
plot(route1000,add=T)
plot(bb)

```

We can see that our rectangular bounding box shape covers a larger area than march route shapes. If we think this bounding box is too large, we can always reduce it in size by lifting new coordinates from OpenStreetMap, converting to a matrix, and generating a smaller spatial bounding box. For now, we will continue with the bounding box we have generated.


```{r}

par(mfrow=c(2,2))

plot(route50)
pts_subset <- points[route50,]
plot(pts_subset, add=T, col="red")


plot(route100)
pts_subset <- points[route100,]
plot(pts_subset, add=T, col="red")

plot(route1000)
pts_subset <- points[route1000,]
plot(pts_subset, add=T, col="red")

plot(bb)
pts_subset <- points[bb,]
plot(pts_subset, add=T, col="red")

```

```{r}
plot(bb, axes=T)
pts_subset <- points[bb,]
plot(pts_subset,add=T)
plot(route50, add=T)
pts_subset <- points[route50,]
plot(pts_subset, add=T, col="red")

plot(bb, axes=T)
pts_subset <- points[bb,]
plot(pts_subset,add=T)
plot(route100, add=T)
pts_subset <- points[route100,]
plot(pts_subset, add=T, col="red")

plot(bb, axes=T)
pts_subset <- points[bb,]
plot(pts_subset,add=T)
plot(route1000, add=T)
pts_subset <- points[route1000,]
plot(pts_subset, add=T, col="red")

plot(bb, axes=T)
pts_subset <- points[bb,]
plot(pts_subset, add=T, col="red")
```

We limit our subsequent analysis to D.C. only, and have provided you with a sample dataset containing a subset of 500 users who tweeted from D.C about the Women's March on the day of the protest. We have changed the names and status ids of all tweets in the data, and have only uploaded information on a few key variables.

To load the dataset, run the following code: 

```{r load DC data, message=F}

# load data
wm_dc <- read_csv("data/wm_dc.csv")

# examine the data 
wm_dc %>% 
  select(status_id, screen_name, created_at, hashtags) %>%
  head(5) %>%
  kbl() %>%
  kable_styling(c("striped", "hover", "condensed", "responsive"))

```

One of the challenges with Twitter data is that it is unclear whether someone who tweets about a protest actually participates in it. Information on the geo-location of users allows us to assess whether or not a user tweeted from within the protest march. The above, using open source GIS softwares, means we can easily locate individuals to within the route of a protest march, providing a confident measure of participation

# Estimating ideology

Once we have located our protestor-users, the esimation of their ideological position (based on their follow network) is straightforward using the `tweetscores` package by Pablo Barberá. We will not estimate the ideologies of our users above as they have been anonymized. But you can certainly look at your own: simply change the user name to your own Twitter username. 

Note: you will also need to set up your authentication token following the steps outlined by Barberá [here](https://github.com/pablobarbera/twitter_ideology)

```{r, eval=FALSE}
library(tweetscores)

user <- "cbarrie"
friends <- getFriends(screen_name=user, oauth = "my_oauth_CB")

ideo <- estimateIdeology2(user, friends)
```



# Some other ways to use Twitter data

This is only the beginning of what we can do with Twitter data. The code below uses the [`tweetbotornot2`](https://github.com/mkearney/tweetbotornot2) package by Michael Kearney, the author of the `rtweet` package  below predicts how many accounts in our dataset are likely bots, and displays some of their content. 

```{r predict bots, warning=F, message = F}
library(remotes) # install remotes package if necessary
library(tweetbotornot2) # install from github if necessary 

bots_p <- predict_bot(blm_tweets)

ggplot(bots_p) +
  geom_histogram(aes(prob_bot)) +
  labs(x= "Probability of being a bot", y= "Count")
```


```{r head bots data, echo = F, message = F}
library(kableExtra) # install if needed

pot_bots <- bots_p$screen_name[bots_p$prob_bot>0.99]

blm_tweets %>%
  filter(screen_name %in% pot_bots) %>%
  select(screen_name, text) %>%
  head(5) %>%
  kbl() %>%
  kable_styling(c("striped", "hover", "condensed", "responsive"))
```



